{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-05-25T17:33:36.313635500Z",
     "start_time": "2023-05-25T17:33:11.655988800Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "error loading _jsonnet (this is expected on Windows), treating C:\\Users\\nek\\AppData\\Local\\Temp\\tmp16m3vt11\\config.json as plain json\n",
      "Some weights of BertModel were not initialized from the model checkpoint at SpanBERT/spanbert-large-cased and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from ners.ner_flair import FlairNer\n",
    "from ners.ner_spacy import SpacyNer\n",
    "from ners.ner_stanza import StanzaNer\n",
    "from helpers.coreference_resolver import CoreferenceResolver\n",
    "from helpers.functions import read_story_from_file, get_file_names, get_characters_from_file, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "error loading _jsonnet (this is expected on Windows), treating C:\\Users\\nek\\AppData\\Local\\Temp\\tmpzlf3i_rb\\config.json as plain json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-25 19:33:49,922 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, S-ORG, S-MISC, B-PER, E-PER, S-LOC, B-ORG, E-ORG, I-PER, S-PER, B-MISC, I-MISC, E-MISC, I-ORG, B-LOC, E-LOC, I-LOC, <START>, <STOP>\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json:   0%|   …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "50c2b03dac074efba975aaa3598e84f0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 19:33:50 INFO: Downloading default packages for language: en (English) ...\n",
      "2023-05-25 19:33:52 INFO: File exists: C:\\Users\\nek\\stanza_resources\\en\\default.zip\n",
      "2023-05-25 19:33:55 INFO: Finished downloading models and saved to C:\\Users\\nek\\stanza_resources.\n",
      "2023-05-25 19:33:55 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json:   0%|   …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "66bf578071c84b5098ff75af40f3b2eb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 19:33:56 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-05-25 19:33:56 INFO: Using device: cpu\n",
      "2023-05-25 19:33:56 INFO: Loading: tokenize\n",
      "2023-05-25 19:33:56 INFO: Loading: pos\n",
      "2023-05-25 19:33:56 INFO: Loading: lemma\n",
      "2023-05-25 19:33:56 INFO: Loading: constituency\n",
      "2023-05-25 19:33:56 INFO: Loading: depparse\n",
      "2023-05-25 19:33:57 INFO: Loading: sentiment\n",
      "2023-05-25 19:33:57 INFO: Loading: ner\n",
      "2023-05-25 19:33:57 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "files = get_file_names()\n",
    "cr = CoreferenceResolver()\n",
    "ner_flair = FlairNer()\n",
    "ner_spacy = SpacyNer()\n",
    "ner_stanza = StanzaNer()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-25T17:33:57.902118500Z",
     "start_time": "2023-05-25T17:33:36.314636200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "a1 = ner_flair.ner_flair(story)\n",
    "a2 = ner_flair.ner_flair(story_cr)\n",
    "b1 = ner_spacy.ner_spacy(story)\n",
    "b2 = ner_spacy.ner_spacy(story_cr)\n",
    "c1 = ner_stanza.ner_stanza(story)\n",
    "c2 = ner_stanza.ner_stanza(story_cr)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-25T16:41:50.327608200Z",
     "start_time": "2023-05-25T16:40:21.913825Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "['002',\n '003',\n '007',\n '011',\n '012',\n '013',\n '014',\n '015',\n '016',\n '017',\n '018',\n '020',\n '021',\n '026',\n '027',\n '029',\n '030',\n '031',\n '032',\n '033',\n '034',\n '035',\n '037',\n '039',\n '040',\n '041',\n 'Androcles',\n 'Avaracious_and_Envious',\n 'Hercules_and_the_Waggoner',\n 'The_Ant_and_the_Grasshopper',\n 'The_Ass_and_the_Lapdog',\n 'The_Ass_in_the_Lions_Skin',\n 'The_Asss_Brains',\n 'The_Bald_Man_and_the_Fly',\n 'The_Cat_Maiden',\n 'The_Cock_and_the_Pearl',\n 'The_Crow_and_the_Pitcher',\n 'The_Dog_and_the_Shadow',\n 'The_Dog_and_the_Wolf',\n 'The_Dog_in_the_Manger',\n 'The_Eagle_and_the_Arrow',\n 'The_Fisher',\n 'The_Fisher_and_the_Little_Fish',\n 'The_Four_Oxen_and_the_Lion',\n 'The_Fox_and_the_Cat',\n 'The_Fox_and_the_Crow',\n 'The_Fox_and_the_Goat',\n 'The_Fox_and_the_Grapes',\n 'The_Fox_and_the_Lion',\n 'The_Fox_and_the_Mask',\n 'The_Fox_and_the_Mosquitoes',\n 'The_Fox_and_the_Stork',\n 'The_Fox_the_Cock_and_the_Dog',\n 'The_Frog_and_the_Ox',\n 'The_Goose_With_the_Golden_Eggs',\n 'The_Hare_With_Many_Friends',\n 'The_Hare_and_the_Tortoise',\n 'The_Hart_and_the_Hunter',\n 'The_Horse_Hunter_and_Stag',\n 'The_Horse_and_the_Ass',\n 'The_Lions_Share',\n 'The_Man_and_the_Serpent',\n 'The_Sick_Lion',\n 'The_Wolf_and_the_Crane',\n 'The_Wolf_and_the_Kid',\n 'The_Wolf_and_the_Lamb',\n 'The_Woodman_and_the_Serpent']"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-25T17:23:11.733312800Z",
     "start_time": "2023-05-25T17:23:11.719301700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "scores = {\"precision\": {\"a1\": [],\n",
    "                        \"a2\": [],\n",
    "                        \"b1\": [],\n",
    "                        \"b2\": [],\n",
    "                        \"c1\": [],\n",
    "                        \"c2\": []},\n",
    "          \"recall\": {\"a1\": [],\n",
    "                        \"a2\": [],\n",
    "                        \"b1\": [],\n",
    "                        \"b2\": [],\n",
    "                        \"c1\": [],\n",
    "                        \"c2\": []},\n",
    "          \"f1\":  {\"a1\": [],\n",
    "                        \"a2\": [],\n",
    "                        \"b1\": [],\n",
    "                        \"b2\": [],\n",
    "                        \"c1\": [],\n",
    "                        \"c2\": []}}\n",
    "\n",
    "shorter_files = [s for s in files if not s.isdigit()]\n",
    "\n",
    "for f in shorter_files:\n",
    "    story = read_story_from_file(f)\n",
    "    story_cr = cr.resolve_coreferences(story)\n",
    "    gt = get_characters_from_file(f)\n",
    "\n",
    "    a1 = ner_flair.ner_flair(story)\n",
    "    a2 = ner_flair.ner_flair(story_cr)\n",
    "\n",
    "    b1 = ner_spacy.ner_spacy(story)\n",
    "    b2 = ner_spacy.ner_spacy(story_cr)\n",
    "\n",
    "    c1 = ner_stanza.ner_stanza(story)\n",
    "    c2 = ner_stanza.ner_stanza(story_cr)\n",
    "\n",
    "    scores[\"precision\"][\"a1\"].append(precision_score(a1, gt))\n",
    "    scores[\"precision\"][\"a2\"].append(precision_score(a2, gt))\n",
    "    scores[\"recall\"][\"a1\"].append(recall_score(a1, gt))\n",
    "    scores[\"recall\"][\"a2\"].append(recall_score(a2, gt))\n",
    "    scores[\"f1\"][\"a1\"].append(f1_score(a1, gt))\n",
    "    scores[\"f1\"][\"a2\"].append(f1_score(a2, gt))\n",
    "\n",
    "    scores[\"precision\"][\"b1\"].append(precision_score(b1, gt))\n",
    "    scores[\"precision\"][\"b2\"].append(precision_score(b2, gt))\n",
    "    scores[\"recall\"][\"b1\"].append(recall_score(b1, gt))\n",
    "    scores[\"recall\"][\"b2\"].append(recall_score(b2, gt))\n",
    "    scores[\"f1\"][\"b1\"].append(f1_score(b1, gt))\n",
    "    scores[\"f1\"][\"b2\"].append(f1_score(b2, gt))\n",
    "\n",
    "    scores[\"precision\"][\"c1\"].append(precision_score(c1, gt))\n",
    "    scores[\"precision\"][\"c2\"].append(precision_score(c2, gt))\n",
    "    scores[\"recall\"][\"c1\"].append(recall_score(c1, gt))\n",
    "    scores[\"recall\"][\"c2\"].append(recall_score(c2, gt))\n",
    "    scores[\"f1\"][\"c1\"].append(f1_score(c1, gt))\n",
    "    scores[\"f1\"][\"c2\"].append(f1_score(c2, gt))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-25T19:47:17.796002700Z",
     "start_time": "2023-05-25T19:34:04.224849700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision\n",
      "a1 0.6969802555168408\n",
      "a2 0.6321718931475029\n",
      "b1 0.46178861788617875\n",
      "b2 0.44227642276422763\n",
      "c1 0.7500580720092915\n",
      "c2 0.7515098722415795\n",
      "recall\n",
      "a1 0.8109756097560976\n",
      "a2 0.7146341463414635\n",
      "b1 0.6382113821138211\n",
      "b2 0.6422764227642277\n",
      "c1 0.8410569105691057\n",
      "c2 0.7808943089430894\n",
      "f1\n",
      "a1 0.7063879210220675\n",
      "a2 0.6266744096012391\n",
      "b1 0.5069105691056912\n",
      "b2 0.5035617499032133\n",
      "c1 0.7564530320627884\n",
      "c2 0.7089430894308945\n"
     ]
    }
   ],
   "source": [
    "def calculate_average(numbers):\n",
    "    if len(numbers) == 0:\n",
    "        return 0  # Handle empty list case\n",
    "\n",
    "    total = sum(numbers)\n",
    "    average = total / len(numbers)\n",
    "    return average\n",
    "\n",
    "\n",
    "for k, v in scores.items():\n",
    "    print(k)\n",
    "    for k1, v1 in v.items():\n",
    "        print(k1 + \" \" + str(calculate_average(v1)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-25T19:52:01.425128Z",
     "start_time": "2023-05-25T19:52:01.410114500Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
